{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bdfb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import matplotlib.style as style\n",
    "#style.available\n",
    "style.use('tableau-colorblind10')\n",
    "# style.use('seaborn-notebook')\n",
    "# style.use('seaborn-whitegrid')\n",
    "\n",
    "# To pre-process and test cleaning results\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faeaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(figname: str):\n",
    "    figname = figname+'.jpg'\n",
    "    figdir = os.getcwd()\n",
    "    filedir = '\\\\'.join([figdir, figname])\n",
    "    plt.savefig(filedir, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd9eaf",
   "metadata": {},
   "source": [
    "# Data Pre-processing for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d40355",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/rock_data.csv')\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c07651",
   "metadata": {},
   "source": [
    "## Main parameters distribution analysis\n",
    "\n",
    "### Density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aad566",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "cols = data_df.columns[4:] # colums to plot - leaving out sample ID, rock #, Class and orientation\n",
    "rows_num = 3 # Subplot grid rows\n",
    "cols_num = int(len(cols)/rows_num) # Subplot grid columns\n",
    "# Plot\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, col in enumerate(cols):\n",
    "    plt.subplot(rows_num, cols_num, i+1)\n",
    "    sns.kdeplot(data=data_df, x=col, shade='fill', hue='Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d843d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Axis Minor Length Distribution per Class')\n",
    "sns.kdeplot(data=data_df, x='Axis Minor Length', shade='fill', hue='Class')\n",
    "save_plot('axis_minor_len_dist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2063a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Max Height Distribution per Class')\n",
    "sns.kdeplot(data=data_df, x='Max Height', shade='fill', hue='Class')\n",
    "save_plot('max_height_dist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0e988",
   "metadata": {},
   "source": [
    "### Comments\n",
    "The main parameters (Perimeter, Area, Axis Major and Minor lengths and Mean Height) seem to show normal distribution. The distribution for the different classes tend to overlap, which will make the classificaiton task harder.\n",
    "\n",
    "Median Height, Max Heaight and STD Height show binomial distributions, again overlapped among classes. \n",
    "\n",
    "## Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "cols = data_df.columns[4:] # colums to plot - leaving out sample ID, rock #, Class and orientation\n",
    "rows_num = 3 # Subplot grid rows\n",
    "cols_num = int(len(cols)/rows_num) # Subplot grid columns\n",
    "# Plot\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, col in enumerate(cols):\n",
    "    plt.subplot(rows_num, cols_num, i+1)\n",
    "    sns.boxplot(data=data_df, y=col, x='Class', orient='v', dodge=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d145e",
   "metadata": {},
   "source": [
    "### Comments\n",
    "In all the main parameters there's an indication of outliers over the high side, with the distribution skewed over the low side.\n",
    "\n",
    "## Parameters correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f77e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pairplot = data_df[data_df.columns[2:9]].drop(columns='Orientation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547959c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data_pairplot, hue='Class',plot_kws={'alpha':0.5})\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2dec1",
   "metadata": {},
   "source": [
    "There's a clear indication of correlation between Perimeter and Area (which makes sense), and a softer correlation between Perimeter & Area with Major and Minor lengths (which also makes sense).\n",
    "\n",
    "### Pearson's Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation\n",
    "df_corr = data_df[data_df.columns[2:]].drop(columns='Orientation').corr()\n",
    "cols = data_df[data_df.columns[2:]].drop(columns='Orientation').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c984827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Correlation Heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df_corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 8},\n",
    "           xticklabels=  cols, \n",
    "           yticklabels=  cols,\n",
    "           cmap= 'coolwarm',\n",
    "           cbar_kws={'label': 'Pearson Correlation'})\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.title('Parameters Pearson Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0e1b0",
   "metadata": {},
   "source": [
    "From the heatmap it can be observed that Area, Perimeter and Axis Major and Minor Length are highly correlated. The same happens with the Height mean, median, max. and standatd deviation, and the gradiend mean, max. and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd5fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countplot per Class\n",
    "order = data_df.Class.unique()\n",
    "plt.title('Sample count by Class')\n",
    "ax = sns.countplot(data=data_df,x='Class', order=order)\n",
    "ax.bar_label(ax.containers[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c707a79",
   "metadata": {},
   "source": [
    "Classes seem to be mostly balanced, with a little imbalance on the middle class (58) respect to classes 12 and 34."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aeefe",
   "metadata": {},
   "source": [
    "## Simple model training\n",
    "This step is done to understand main predictors and impact of removal of correlated parameters. The same for outliers removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[data_df.columns[4:]].to_numpy()\n",
    "y = data_df['Class'].to_numpy()\n",
    "# Train/Test Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95705166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple classifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "# Get Feature Importances\n",
    "importances = tree_clf.feature_importances_\n",
    "columns = data_df.columns[4:]\n",
    "importances_df = pd.DataFrame({'feature_name': columns,\n",
    "                               'feature_importance': importances})\n",
    "importances_df = importances_df.sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=importances_df.feature_name, y=importances_df.feature_importance)\n",
    "plt.title('Feature importance - Test model',fontsize=14, fontweight = 'black')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel(\"Dataset features - Test model\",fontsize=12, fontweight = 'black')\n",
    "plt.ylabel(\"Feature importance [0 to 1]\",fontsize=12, fontweight = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=tree_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=tree_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36cd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_report(y_val, model_best_pred, m, model_names, tree_clf, dataset, opt_method):\n",
    "    \"\"\"\n",
    "    Parse classification report valeus to dataframe for posterior comparison of model performance.\n",
    "    Returns:\n",
    "    --------\n",
    "    df: classification report values dataframe\n",
    "    \"\"\"\n",
    "    report = classification_report(y_val, model_best_pred, output_dict=True)\n",
    "    dict_values = {}\n",
    "    dict_values['model']=model_names[m]\n",
    "    dict_values['params']=np.array([tree_clf.get_params()])\n",
    "    dict_values['dataset']=dataset\n",
    "    dict_values['opt_method']=opt_method\n",
    "    for elem, score in report.items():\n",
    "        try:\n",
    "            for score_name, score_num in score.items():\n",
    "                if elem.isnumeric():\n",
    "                    col_i = '_'.join(['class', elem.replace(\" \", \"_\"), score_name])\n",
    "                else:\n",
    "                    col_i = '_'.join([elem.replace(\" \", \"_\"), score_name])\n",
    "                dict_values[col_i] = score_num\n",
    "#                 col = np.append(col, col_i)\n",
    "        except:\n",
    "            col_i = elem\n",
    "            dict_values[col_i] = score_num\n",
    "#             col = np.append(col, col_i)\n",
    "            continue\n",
    "    df = pd.DataFrame(dict_values, index=[m])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46188ea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = ['12', '34', '58']\n",
    "print(classification_report(y_test, y_pred, target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ = parse_report(y_test, y_pred, 0, ['DecisionTreeClassifier'], tree_clf, 'mean_height', 'no_optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b95ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_.to_csv('simple_tree_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9163a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f12c6",
   "metadata": {},
   "source": [
    "### Train simple model with main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37850120",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = importances_df['feature_name'].iloc[:7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4bd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[cols].to_numpy()\n",
    "y = data_df['Class'].to_numpy()\n",
    "# Train/Test Split Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple classifier\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "tree_clf.fit(X_train, y_train)\n",
    "# Get Feature Importances\n",
    "importances = tree_clf.feature_importances_\n",
    "# columns = data_df.columns[4:]\n",
    "importances_df = pd.DataFrame({'feature_name': cols,\n",
    "                               'feature_importance': importances})\n",
    "importances_df = importances_df.sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=importances_df.feature_name, y=importances_df.feature_importance)\n",
    "plt.title('Feature importance - Test model',fontsize=14, fontweight = 'black')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.xlabel(\"Dataset features - Test model\",fontsize=12, fontweight = 'black')\n",
    "plt.ylabel(\"Feature importance [0 to 1]\",fontsize=12, fontweight = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377cdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=tree_clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=tree_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a67dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = ['12', '34', '58']\n",
    "print(classification_report(y_test, y_pred, target_names=target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
