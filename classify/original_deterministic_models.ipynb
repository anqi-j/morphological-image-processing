{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import *\n",
    "import os\n",
    "from scipy.stats import zscore\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.inspection import partial_dependence, PartialDependenceDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import shap\n",
    "import lime\n",
    "from PyALE import ale\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.style as style\n",
    "#style.available\n",
    "style.use('tableau-colorblind10')\n",
    "# style.use('seaborn-notebook')\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "random_state = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(figname: str):\n",
    "    figname = figname+'.jpg'\n",
    "    figdir = os.getcwd()\n",
    "    filedir = '\\\\'.join([figdir, figname])\n",
    "    plt.savefig(filedir, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rock_data.csv')\n",
    "\n",
    "# handle missing values\n",
    "if df.isnull().values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print('Missing values filled with mean.')\n",
    "\n",
    "# detect and remove outliers\n",
    "\n",
    "# drop highly correlated features\n",
    "df.drop(['Area', 'Perimeter','Median Height', 'Max Height', 'STD Height'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:].to_numpy(dtype=float)\n",
    "\n",
    "def map_class_values(x):\n",
    "    mapping = {12: 0, 58: 1, 34: 2}\n",
    "    return mapping.get(x,None)\n",
    "\n",
    "y = np.vectorize(map_class_values)(df['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:validation:testing = 60:20:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'SVC', 'RF', 'XGB', 'TREE', 'MLP']\n",
    "models = [KNeighborsClassifier(), SVC(), RandomForestClassifier(), XGBClassifier(), DecisionTreeClassifier(), MLPClassifier(max_iter=500)]\n",
    "grid_params = [{'n_neighbors': [5, 10, 15, 20], 'weights': ['uniform', 'distance']}, {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'sigmoid']}, {'n_estimators': [10, 100, 200], 'criterion': ['gini', 'entropy', 'log_loss'], 'max_features': ['sqrt', 'log2', None]}, {'max_depth': [3,5,7], 'n_estimators': [10, 100, 200], 'reg_lambda': [1e-3, 1, 1e3]}, {'criterion': ['gini', 'entropy', 'log_loss'],'max_depth': [3,5,7]}, {'hidden_layer_sizes': [(100,), (100,50), (100,50,100)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'alpha': [1e-3, 1, 1e3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method):\n",
    "    \"\"\"\n",
    "    Parse classification report valeus to dataframe for posterior comparison of model performance.\n",
    "    Returns:\n",
    "    --------\n",
    "    df: classification report values dataframe\n",
    "    \"\"\"\n",
    "    report = classification_report(y_val, model_best_pred, output_dict=True)\n",
    "    dict_values = {}\n",
    "    dict_values['model']=model_names[m]\n",
    "    dict_values['params']=np.array([grid_search.best_params_])\n",
    "    dict_values['dataset']=dataset\n",
    "    dict_values['opt_method']=opt_method\n",
    "    for elem, score in report.items():\n",
    "        try:\n",
    "            for score_name, score_num in score.items():\n",
    "                if elem.isnumeric():\n",
    "                    col_i = '_'.join(['class', elem.replace(\" \", \"_\"), score_name])\n",
    "                else:\n",
    "                    col_i = '_'.join([elem.replace(\" \", \"_\"), score_name])\n",
    "                dict_values[col_i] = score_num\n",
    "#                 col = np.append(col, col_i)\n",
    "        except:\n",
    "            col_i = elem\n",
    "            dict_values[col_i] = score_num\n",
    "#             col = np.append(col, col_i)\n",
    "            continue\n",
    "    df = pd.DataFrame(dict_values, index=[m])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'mean_height'\n",
    "opt_method = 'grid_search'\n",
    "for m,model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, grid_params[m], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_best = grid_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    if m==0:\n",
    "        results_df = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "    else:\n",
    "        df_i = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "        results_df = pd.concat([results_df, df_i])\n",
    "    # Print results\n",
    "    print(f'{model_names[m]} with {grid_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = [{\n",
    "    'n_neighbors': Integer(3,50),\n",
    "    'weights': Categorical(['uniform', 'distance'])\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'C': Real(0.1, 10, 'log-uniform'),\n",
    "    'kernel': Categorical(['linear', 'rbf', 'sigmoid']),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "    'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'max_depth': Integer(3,10),\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'reg_lambda': Real(1e-3, 1e3, 'log-uniform'),\n",
    "    },\n",
    "    {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,5,7]\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'mean_height'\n",
    "opt_method = 'bayes_search'\n",
    "for m,model in enumerate(models[:-1]):\n",
    "    bayes_search = BayesSearchCV(model, search_spaces[m], n_iter=50, cv=5, n_jobs=-1)\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    model_best = bayes_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    df_i = parse_report(y_val, model_best_pred, m, model_names, bayes_search, dataset, opt_method)\n",
    "    results_df = pd.concat([results_df, df_i])\n",
    "    print(f'{model_names[m]} with {bayes_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = [KNeighborsClassifier(n_neighbors=15, weights= 'distance'), SVC(C=10, kernel='rbf'), RandomForestClassifier(criterion='log_loss', max_features= 'sqrt', n_estimators=200), XGBClassifier(max_depth=3, n_estimators=100, reg_lambda=1), MLPClassifier(max_iter=500, activation='logistic', alpha=0.001, hidden_layer_sizes=(100,50))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m,model in enumerate(best_models):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'{model} \\n {classification_report(y_test, y_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = KNeighborsClassifier(n_neighbors=15, weights='distance') \n",
    "       \n",
    "labels = ['Uncalibrated', 'Isotonic', 'Sigmoid']\n",
    "classes = ['12', '58', '34']\n",
    "colors= ['r', 'g', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cal, y_train, y_cal = train_test_split(X, y, test_size=0.3, random_state=random_state+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SVC(C=0.1, kernel='linear', probability=True)\n",
    "best_model_cal_iso = CalibratedClassifierCV(best_model, method='isotonic')\n",
    "best_model_cal_sig = CalibratedClassifierCV(best_model, method='sigmoid')\n",
    "models = [best_model, best_model_cal_iso, best_model_cal_sig]\n",
    "\n",
    "fig, axs = subplots(nrows=1, ncols=3, figsize=(16,4))\n",
    "\n",
    "for m, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "for i in range(3):\n",
    "    for m, model in enumerate(models):\n",
    "        y_pred = model.predict_proba(X_cal)\n",
    "        y_cal_b = np.vectorize(lambda x: 1 if x==i else 0)(y_cal)\n",
    "        y_pred_b = y_pred[:,i]\n",
    "\n",
    "        fop, mpv = calibration_curve(y_cal_b, (y_pred_b-y_pred_b.min())/y_pred_b.ptp(), n_bins=10)\n",
    "\n",
    "        axs[i].plot(fop, mpv, color=colors[m], linestyle='-', linewidth=3, label=labels[m])\n",
    "\n",
    "    axs[i].plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=3, label='Ideal')\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].set_ylim([0, 1])\n",
    "    axs[i].set_xlabel('Fraction of positives', fontsize=24)\n",
    "    axs[i].set_ylabel('Mean predicted value', fontsize=24)\n",
    "    axs[i].set_title(f'{classes[i]} vs. else', fontsize=24)\n",
    "    \n",
    "    if i==0:\n",
    "        axs[i].legend(loc='best' , fontsize=12)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = subplots(nrows=1, ncols=3, figsize=(16,4))\n",
    "\n",
    "for i in range(3):\n",
    "    best_model = SVC(C=0.1, kernel='linear', probability=True)\n",
    "    best_model_cal_iso = CalibratedClassifierCV(best_model, method='isotonic')\n",
    "    best_model_cal_sig = CalibratedClassifierCV(best_model, method='sigmoid')\n",
    "    models = [best_model, best_model_cal_iso, best_model_cal_sig]\n",
    "    for m, model in enumerate(models):\n",
    "        \n",
    "        y_train_b = np.vectorize(lambda x: 1 if x==i else 0)(y_train)\n",
    "        model.fit(X_train, y_train_b)\n",
    "        \n",
    "        y_pred = model.predict_proba(X_cal)\n",
    "        y_cal_b = np.vectorize(lambda x: 1 if x==i else 0)(y_cal)\n",
    "        y_pred_b = y_pred[:,1]\n",
    "\n",
    "        fop, mpv = calibration_curve(y_cal_b, (y_pred_b-y_pred_b.min())/y_pred_b.ptp(), n_bins=10)\n",
    "\n",
    "        axs[i].plot(fop, mpv, color=colors[m], linestyle='-', linewidth=3, label=labels[m])\n",
    "\n",
    "    axs[i].plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=3, label='Ideal')\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].set_ylim([0, 1])\n",
    "    axs[i].set_xlabel('Fraction of positives', fontsize=24)\n",
    "    axs[i].set_ylabel('Mean predicted value', fontsize=24)\n",
    "    axs[i].set_title(f'{classes[i]} vs. else', fontsize=24)\n",
    "    \n",
    "    if i==0:\n",
    "        axs[i].legend(loc='best' , fontsize=12)\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state+4)\n",
    "\n",
    "for m, model in enumerate(models):\n",
    "        model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = subplots(nrows=1, ncols=3, figsize=(16,4))\n",
    "\n",
    "for i in range(3):\n",
    "    best_model = SVC(C=0.1, kernel='linear', probability=True)\n",
    "    best_model_cal_iso = CalibratedClassifierCV(best_model, method='isotonic')\n",
    "    best_model_cal_sig = CalibratedClassifierCV(best_model, method='sigmoid')\n",
    "    models = [best_model, best_model_cal_iso, best_model_cal_sig]\n",
    "    for m, model in enumerate(models):\n",
    "        \n",
    "        y_train_b = np.vectorize(lambda x: 1 if x==i else 0)(y_train)\n",
    "        model.fit(X_train, y_train_b)\n",
    "        \n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        y_test_b = np.vectorize(lambda x: 1 if x==i else 0)(y_test)\n",
    "        y_pred_b = y_pred[:,1]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test_b, y_pred_b)\n",
    "\n",
    "        axs[i].plot(fpr, tpr, color=colors[m], linestyle='--', linewidth=3, label=labels[m])\n",
    "        axs[i].text(0.7, 0.6-0.05*m, f'AUC={auc(fpr, tpr):.2f}', color=colors[m], fontsize=12)\n",
    "\n",
    "    axs[i].plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=3)\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].set_ylim([0, 1])\n",
    "    axs[i].set_xlabel('False Positive Rate', fontsize=24)\n",
    "    axs[i].set_ylabel('True Positive Rate', fontsize=24)\n",
    "    axs[i].set_title(f'{classes[i]} vs. else', fontsize=24)\n",
    "    \n",
    "\n",
    "    if i==0:\n",
    "        axs[i].legend(loc='best' , fontsize=12)\n",
    "            \n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = SVC(C=0.1, kernel='linear', probability=True)\n",
    "best_model_cal_iso = CalibratedClassifierCV(best_model, method='isotonic')\n",
    "best_model_cal_sig = CalibratedClassifierCV(best_model, method='sigmoid')\n",
    "models = [best_model, best_model_cal_iso, best_model_cal_sig]\n",
    "\n",
    "fig, axs = subplots(nrows=1, ncols=3, figsize=(16,4))\n",
    "\n",
    "for m, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "for i in range(3):\n",
    "    for m, model in enumerate(models):\n",
    "        y_pred = model.predict_proba(X_test)\n",
    "        y_test_b = np.vectorize(lambda x: 1 if x==i else 0)(y_test)\n",
    "        y_pred_b = y_pred[:,i]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test_b, y_pred_b)\n",
    "\n",
    "        axs[i].plot(fpr, tpr, color=colors[m], linestyle='--', linewidth=3, label=labels[m])\n",
    "        axs[i].text(0.7, 0.6-0.05*m, f'AUC={auc(fpr, tpr):.2f}', color=colors[m], fontsize=12)\n",
    "\n",
    "    axs[i].plot([0, 1], [0, 1], color='gray', linestyle='--', linewidth=3)\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].set_ylim([0, 1])\n",
    "    axs[i].set_xlabel('False Positive Rate', fontsize=24)\n",
    "    axs[i].set_ylabel('True Positive Rate', fontsize=24)\n",
    "    axs[i].set_title(f'{classes[i]} vs. else', fontsize=24)\n",
    "    \n",
    "    if i==0:\n",
    "        axs[i].legend(loc='best' , fontsize=12)\n",
    "            \n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(criterion='log_loss', n_estimators=200)\n",
    "best_model.fit(X, y)\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,0], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,2], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,1,0], color=shap_values[:,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,1,1], color=shap_values[:,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,1,2], color=shap_values[:,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "best_model.fit(X, y)\n",
    "features_PDP = [\"Axis Major Length\", \"Axis Minor Length\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_eff = ale(X=X, model=best_model, feature=[\"Axis Minor Length\"], grid_size=20, include_CI=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ale_eff = ale(X=X, model=best_model, feature=features_PDP, grid_size=20, include_CI=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X.to_numpy(), class_names=['12', '58', '34'], feature_names = X.columns, kernel_width=2, mode='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, X.shape[0])\n",
    "exp = explainer.explain_instance(X.iloc[i,:], best_model.predict_proba, num_features=X.shape[1], top_labels=1)\n",
    "exp.save_to_file(f'original_lime_row{i}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training - change Mean height to Max Height (based on SHAP results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rock_data.csv')\n",
    "\n",
    "# handle missing values\n",
    "if df.isnull().values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print('Missing values filled with mean.')\n",
    "\n",
    "# detect and remove outliers\n",
    "\n",
    "# drop highly correlated features\n",
    "df.drop(['Area', 'Perimeter','Median Height', 'Mean Height', 'STD Height'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:].to_numpy(dtype=float)\n",
    "\n",
    "def map_class_values(x):\n",
    "    mapping = {12: 0, 58: 1, 34: 2}\n",
    "    return mapping.get(x,None)\n",
    "\n",
    "y = np.vectorize(map_class_values)(df['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:validation:testing = 60:20:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'SVC', 'RF', 'XGB', 'MLP']\n",
    "models = [KNeighborsClassifier(), SVC(), RandomForestClassifier(), XGBClassifier(), MLPClassifier(max_iter=500)]\n",
    "grid_params = [{'n_neighbors': [5, 10, 15, 20], 'weights': ['uniform', 'distance']}, {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'sigmoid']}, {'n_estimators': [10, 100, 200], 'criterion': ['gini', 'entropy', 'log_loss'], 'max_features': ['sqrt', 'log2', None]}, {'max_depth': [3,5,7], 'n_estimators': [10, 100, 200], 'reg_lambda': [1e-3, 1, 1e3]}, {'hidden_layer_sizes': [(100,), (100,50), (100,50,100)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'alpha': [1e-3, 1, 1e3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'grid_search'\n",
    "for m,model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, grid_params[m], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_best = grid_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "#     if m==0:\n",
    "#         results_df = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset)\n",
    "#     else:\n",
    "    df_i = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "    results_df = pd.concat([results_df, df_i])\n",
    "    # Print results\n",
    "    print(f'{model_names[m]} with {grid_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = [{\n",
    "    'n_neighbors': Integer(3,50),\n",
    "    'weights': Categorical(['uniform', 'distance'])\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'C': Real(0.1, 10, 'log-uniform'),\n",
    "    'kernel': Categorical(['linear', 'rbf', 'sigmoid']),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "    'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'max_depth': Integer(3,10),\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'reg_lambda': Real(1e-3, 1e3, 'log-uniform'),\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'bayes_search'\n",
    "for m,model in enumerate(models[:-1]):\n",
    "    bayes_search = BayesSearchCV(model, search_spaces[m], n_iter=50, cv=5, n_jobs=-1)\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    model_best = bayes_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    df_i = parse_report(y_val, model_best_pred, m, model_names, bayes_search, dataset, opt_method)\n",
    "    results_df = pd.concat([results_df, df_i])\n",
    "    print(f'{model_names[m]} with {bayes_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['opt_method_dataset']=results_df['opt_method']+'_'+results_df['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.title('Model Comparison - Grid or Bayes Search \\nDataset with Max or Mean Height')\n",
    "sns.barplot(x=results_df['model'], y=results_df['weighted_avg_f1-score'], hue=results_df['opt_method_dataset'])\n",
    "plt.ylim(0.6, 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Model Comparison\\nDataset with Max or Mean Height')\n",
    "sns.barplot(x=results_df['model'], y=results_df['weighted_avg_f1-score'], hue=results_df['dataset'])\n",
    "plt.ylim(0.6, 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rock_data.csv')\n",
    "\n",
    "# handle missing values\n",
    "if df.isnull().values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print('Missing values filled with mean.')\n",
    "\n",
    "# detect and remove outliers\n",
    "\n",
    "# drop highly correlated features\n",
    "df.drop(['Area', 'Perimeter','Median Height', 'Mean Height', 'STD Height'], axis=1, inplace=True)\n",
    "df.columns\n",
    "\n",
    "X = df.iloc[:,3:]#.to_numpy(dtype=float)\n",
    "y = df['Class'].values #np.vectorize(map_class_values)(df['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model - from plot\n",
    "model_mask = (results_df['model']=='SVC')\n",
    "dataset_mask = (results_df['dataset']=='max_height')\n",
    "opt_method_mask = (results_df['opt_method']=='grid_search')\n",
    "mask = model_mask & dataset_mask & opt_method_mask\n",
    "params_best_model = results_df['params'][mask].values[0]\n",
    "results_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = SVC(C= params_best_model['C'], kernel= params_best_model['kernel'])\n",
    "best_model = RandomForestClassifier(criterion= params_best_model['criterion'], \n",
    "                                    max_features= params_best_model['max_features'], \n",
    "                                    n_estimators= params_best_model['n_estimators'])\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# svm_explainer = shap.KernelExplainer(best_model.predict,X_test)\n",
    "# shap_values = svm_explainer.shap_values(X_test)\n",
    "\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,0], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,1], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,:,2], X, max_display=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,2,0], color=shap_values[:,3,0])\n",
    "save_plot('shap_scatter_minor len vs max H_class 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,2,1], color=shap_values[:,3,1])\n",
    "save_plot('shap_scatter_minor len vs max H_class 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.scatter(shap_values[:,2,2], color=shap_values[:,3,2])\n",
    "save_plot('shap_scatter_minor len vs max H_class 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "# best_model.fit(X, y)\n",
    "features_PDP = [\"Axis Minor Length\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=0)\n",
    "save_plot('pdp_axis minor len_class 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_PDP = [\"Axis Minor Length\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=1)\n",
    "save_plot('pdp_axis minor len_class 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_PDP = [\"Axis Minor Length\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=2)\n",
    "save_plot('pdp_axis minor len_class 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "# best_model.fit(X, y)\n",
    "features_PDP = [\"Max Height\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=0)\n",
    "save_plot('pdp_axis minor len_class 0_max h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_PDP = [\"Max Height\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=1)\n",
    "save_plot('pdp_axis minor len_class 1_max h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_PDP = [\"Max Height\"]\n",
    "PartialDependenceDisplay.from_estimator(best_model, X, features_PDP, kind='both', target=2)\n",
    "save_plot('pdp_axis minor len_class 2_max h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance - Waterfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[100,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('models_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rock_data.csv')\n",
    "\n",
    "# handle missing values\n",
    "if df.isnull().values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print('Missing values filled with mean.')\n",
    "\n",
    "# detect and remove outliers\n",
    "\n",
    "# drop highly correlated features\n",
    "df.drop(['Area', 'Perimeter','Median Height', 'Mean Height', 'STD Height', 'Orientation','Sample ID', 'Rock ID'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:].to_numpy(dtype=float)\n",
    "\n",
    "def map_class_values(x):\n",
    "    mapping = {12: 0, 58: 1, 34: 2}\n",
    "    return mapping.get(x,None)\n",
    "\n",
    "y = np.vectorize(map_class_values)(df['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:validation:testing = 60:20:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'SVC', 'RF', 'XGB', 'TREE', 'MLP']\n",
    "models = [KNeighborsClassifier(), SVC(), RandomForestClassifier(), XGBClassifier(), DecisionTreeClassifier(), MLPClassifier(max_iter=500)]\n",
    "grid_params = [{'n_neighbors': [5, 10, 15, 20], 'weights': ['uniform', 'distance']}, {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'sigmoid']}, {'n_estimators': [10, 100, 200], 'criterion': ['gini', 'entropy', 'log_loss'], 'max_features': ['sqrt', 'log2', None]}, {'max_depth': [3,5,7], 'n_estimators': [10, 100, 200], 'reg_lambda': [1e-3, 1, 1e3]}, {'criterion': ['gini', 'entropy', 'log_loss'],'max_depth': [3,5,7]}, {'hidden_layer_sizes': [(100,), (100,50), (100,50,100)], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'alpha': [1e-3, 1, 1e3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'grid_search'\n",
    "for m,model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, grid_params[m], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_best = grid_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    if m==0:\n",
    "        results_df_drop = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "    else:\n",
    "        df_i = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "        results_df_drop = pd.concat([results_df_drop, df_i])\n",
    "    # Print results\n",
    "    print(f'{model_names[m]} with {grid_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = [{\n",
    "    'n_neighbors': Integer(3,50),\n",
    "    'weights': Categorical(['uniform', 'distance'])\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'C': Real(0.1, 10, 'log-uniform'),\n",
    "    'kernel': Categorical(['linear', 'rbf', 'sigmoid']),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "    'max_features': Categorical(['sqrt', 'log2', None]),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'max_depth': Integer(3,10),\n",
    "    'n_estimators': Integer(10,200),\n",
    "    'reg_lambda': Real(1e-3, 1e3, 'log-uniform'),\n",
    "    },\n",
    "    {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [3,5,7]\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'bayes_search'\n",
    "for m,model in enumerate(models[:-1]):\n",
    "    bayes_search = BayesSearchCV(model, search_spaces[m], n_iter=50, cv=5, n_jobs=-1)\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    model_best = bayes_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    df_i = parse_report(y_val, model_best_pred, m, model_names, bayes_search, dataset, opt_method)\n",
    "    results_df_drop = pd.concat([results_df_drop, df_i])\n",
    "    print(f'{model_names[m]} with {bayes_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-score normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rock_data.csv')\n",
    "\n",
    "# handle missing values\n",
    "if df.isnull().values.any():\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    print('Missing values filled with mean.')\n",
    "\n",
    "# detect and remove outliers\n",
    "\n",
    "# drop highly correlated features\n",
    "df.drop(['Area', 'Perimeter','Median Height', 'Mean Height', 'STD Height'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,3:].to_numpy(dtype=float)\n",
    "\n",
    "def map_class_values(x):\n",
    "    mapping = {12: 0, 58: 1, 34: 2}\n",
    "    return mapping.get(x,None)\n",
    "\n",
    "y = np.vectorize(map_class_values)(df['Class'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:validation:testing = 60:20:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['KNN', 'SVC', 'RF', 'XGB', 'TREE', 'MLP']\n",
    "knn = Pipeline([('scaler', StandardScaler()), ('knn', KNeighborsClassifier())])\n",
    "svc = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "rf = Pipeline([('scaler', StandardScaler()), ('rf', RandomForestClassifier())])\n",
    "xgb = Pipeline([('scaler', StandardScaler()), ('xgb', XGBClassifier())])\n",
    "tree = Pipeline([('scaler', StandardScaler()), ('tree', DecisionTreeClassifier())])\n",
    "mlp = Pipeline([('scaler', StandardScaler()), ('mlp', MLPClassifier(max_iter=500))])\n",
    "models = [knn, svc, rf, xgb, tree, mlp]\n",
    "grid_params = [{'knn__n_neighbors': [5, 10, 15, 20], 'knn__weights': ['uniform', 'distance']}, \n",
    "               {'svc__C': [0.1, 1, 10], 'svc__kernel': ['linear', 'rbf', 'sigmoid']}, \n",
    "               {'rf__n_estimators': [10, 100, 200], 'rf__criterion': ['gini', 'entropy', 'log_loss'], 'rf__max_features': ['sqrt', 'log2', None]}, \n",
    "               {'xgb__max_depth': [3,5,7], 'xgb__n_estimators': [10, 100, 200], 'xgb__reg_lambda': [1e-3, 1, 1e3]}, \n",
    "               {'tree__criterion': ['gini', 'entropy', 'log_loss'],'tree__max_depth': [3,5,7]}, \n",
    "               {'mlp__hidden_layer_sizes': [(100,), (100,50), (100,50,100)], 'mlp__activation': ['identity', 'logistic', 'tanh', 'relu'], 'mlp__alpha': [1e-3, 1, 1e3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'grid_search'\n",
    "for m,model in enumerate(models):\n",
    "    grid_search = GridSearchCV(model, grid_params[m], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    model_best = grid_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    if m==0:\n",
    "        results_df_norm = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "    else:\n",
    "        df_i = parse_report(y_val, model_best_pred, m, model_names, grid_search, dataset, opt_method)\n",
    "        results_df_norm = pd.concat([results_df_norm, df_i])\n",
    "    # Print results\n",
    "    print(f'{model_names[m]} with {grid_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Search Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = [{\n",
    "    'knn__n_neighbors': Integer(3,50),\n",
    "    'knn__weights': Categorical(['uniform', 'distance'])\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'svc__C': Real(0.1, 10, 'log-uniform'),\n",
    "    'svc__kernel': Categorical(['linear', 'rbf', 'sigmoid']),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'rf__n_estimators': Integer(10,200),\n",
    "    'rf__criterion': Categorical(['gini', 'entropy', 'log_loss']),\n",
    "    'rf__max_features': Categorical(['sqrt', 'log2', None]),\n",
    "    },\n",
    "    \n",
    "    {\n",
    "    'xgb__max_depth': Integer(3,10),\n",
    "    'xgb__n_estimators': Integer(10,200),\n",
    "    'xgb__reg_lambda': Real(1e-3, 1e3, 'log-uniform'),\n",
    "    },\n",
    "    {\n",
    "    'tree__criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'tree__max_depth': Integer(3,10)\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = 'max_height'\n",
    "opt_method = 'bayes_search'\n",
    "for m,model in enumerate(models[:-1]):\n",
    "    bayes_search = BayesSearchCV(model, search_spaces[m], n_iter=50, cv=5, n_jobs=-1)\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "    model_best = bayes_search.best_estimator_\n",
    "    model_best_pred = model_best.predict(X_val)\n",
    "    # Parse report to dataframe to compare results among models\n",
    "    df_i = parse_report(y_val, model_best_pred, m, model_names, bayes_search, dataset, opt_method)\n",
    "    results_df_norm = pd.concat([results_df_norm, df_i])\n",
    "    print(f'{model_names[m]} with {bayes_search.best_params_} \\n {classification_report(y_val, model_best_pred)}\\n')\n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_val, model_best_pred)).plot()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.reset_index(drop=True).iloc[:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['test'] = 'original'\n",
    "results_df_drop['test'] = 'drop_orientation'\n",
    "results_df_norm['test'] = 'z-score_norm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_final = pd.concat([results_df, results_df_drop, results_df_norm]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask = results_final['test'] != 'z-score_norm'\n",
    "plt.title('Model Comparison\\nOriginal vs. Drop Orientation Dataset')\n",
    "sns.barplot(x=results_final['model'][mask], y=results_final['weighted_avg_f1-score'][mask], hue=results_final['test'][mask])\n",
    "plt.ylim(0.5, 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results_final['test'] != 'drop_orientation'\n",
    "plt.title('Model Comparison\\nOriginal vs. Z-score Normalization Dataset')\n",
    "sns.barplot(x=results_final['model'][mask], y=results_final['weighted_avg_f1-score'][mask], hue=results_final['test'][mask])\n",
    "plt.ylim(0.6, 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
